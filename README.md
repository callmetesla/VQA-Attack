# VQA-Attack

VQA is at the intersection of Visual understanding and Language understanding problems. The language model focuses on understanding the contextual meaning of the question posed. The visual model was adaptively built to extract the relevant features from the input image using the tokens generated by the language model. The project consisted of an LSTM network and a VQA network in a cascading architecture. The VQA network was primarily built on top of the ResNet model. The project made use of the MS-COCO and VQA datasets for training and testing.<br/>
For more info refer: [PDF](VQA.pdf)
